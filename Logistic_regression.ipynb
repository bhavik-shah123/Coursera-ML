{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNy6K9TdCe6dHRXI6W/CPRv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhavik-shah123/Coursera-ML/blob/master/Logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZb_1EW-hTFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40f14f8d-2110-474f-c626-1bc7c3918e41"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXMv1yY4tURG",
        "colab_type": "text"
      },
      "source": [
        "###yhat = 1.0 / (1.0 + e^(-(b0 + b1 * x1)))\n",
        "###b = b + learning_rate * (y - yhat) * yhat * (1 - yhat) * x\n",
        "\n",
        "##Procedure followed\n",
        "1. Dataset is loaded and then normalized using dataset_minmax() and normalize_dataset().\n",
        "2.  method is used to estimate the performance of the learned model on unseen data\n",
        "3. Predict() function uses yhat, i.e Cost Function for Logistic Regression to predict output values.\n",
        "Parameter theta(coefficients) is obtained using the above mentioned formula.\n",
        "4. Gradient Descent is used to find the best coefficient\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOF__kYdrY3s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d1a9ea57-730e-4b81-8da2-1e7afb979674"
      },
      "source": [
        "# Logistic Regression on Diabetes Dataset\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from csv import reader\n",
        "from math import exp\n",
        "\n",
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset\n",
        "\n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        "\n",
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "\tminmax = list()\n",
        "\tfor i in range(len(dataset[0])):\n",
        "\t\tcol_values = [row[i] for row in dataset]\n",
        "\t\tvalue_min = min(col_values)\n",
        "\t\tvalue_max = max(col_values)\n",
        "\t\tminmax.append([value_min, value_max])\n",
        "\treturn minmax\n",
        "\n",
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "\tfor row in dataset:\n",
        "\t\tfor i in range(len(row)):\n",
        "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
        "\n",
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / n_folds)\n",
        "\tfor i in range(n_folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split\n",
        "\n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0\n",
        "\n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\n",
        "\tscores = list()\n",
        "\tfor fold in folds:\n",
        "\t\ttrain_set = list(folds)\n",
        "\t\ttrain_set.remove(fold)\n",
        "\t\ttrain_set = sum(train_set, [])\n",
        "\t\ttest_set = list()\n",
        "\t\tfor row in fold:\n",
        "\t\t\trow_copy = list(row)\n",
        "\t\t\ttest_set.append(row_copy)\n",
        "\t\t\trow_copy[-1] = None\n",
        "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
        "\t\tactual = [row[-1] for row in fold]\n",
        "\t\taccuracy = accuracy_metric(actual, predicted)\n",
        "\t\tscores.append(accuracy)\n",
        "\treturn scores\n",
        "\n",
        "# Make a prediction with coefficients\n",
        "def predict(row, coefficients):\n",
        "\tyhat = coefficients[0]\n",
        "\tfor i in range(len(row)-1):\n",
        "\t\tyhat += coefficients[i + 1] * row[i]\n",
        "\treturn 1.0 / (1.0 + exp(-yhat))\n",
        "\n",
        "# Estimate logistic regression coefficients using stochastic gradient descent\n",
        "def coefficients_sgd(train, l_rate, n_epoch):\n",
        "\tcoef = [0.0 for i in range(len(train[0]))]\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tfor row in train:\n",
        "\t\t\tyhat = predict(row, coef)\n",
        "\t\t\terror = row[-1] - yhat\n",
        "\t\t\tcoef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)\n",
        "\t\t\tfor i in range(len(row)-1):\n",
        "\t\t\t\tcoef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]\n",
        "\treturn coef\n",
        "\n",
        "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
        "def logistic_regression(train, test, l_rate, n_epoch):\n",
        "\tpredictions = list()\n",
        "\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n",
        "\tfor row in test:\n",
        "\t\tyhat = predict(row, coef)\n",
        "\t\tyhat = round(yhat)\n",
        "\t\tpredictions.append(yhat)\n",
        "\treturn(predictions)\n",
        "\n",
        "# Test the logistic regression algorithm on the diabetes dataset\n",
        "seed(1)\n",
        "# load and prepare data\n",
        "filename = '/content/drive/My Drive/SEM4/pima-indians-diabetes.csv'\n",
        "dataset = load_csv(filename)\n",
        "for i in range(len(dataset[0])):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# normalize\n",
        "minmax = dataset_minmax(dataset)\n",
        "normalize_dataset(dataset, minmax)\n",
        "# evaluate algorithm\n",
        "n_folds = 5\n",
        "l_rate = 0.1\n",
        "n_epoch = 100\n",
        "scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [73.8562091503268, 78.43137254901961, 81.69934640522875, 75.81699346405229, 75.81699346405229]\n",
            "Mean Accuracy: 77.124%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}